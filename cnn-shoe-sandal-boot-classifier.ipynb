{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/matthewweisberg/97-5-accuracy-cnn-classifier?scriptVersionId=110458855\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"### Import Packages","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport tensorflow.keras.layers as layers\nimport cv2\nimport random\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder\nfrom skimage.transform import resize\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix ","metadata":{"execution":{"iopub.status.busy":"2022-11-09T02:58:44.633065Z","iopub.execute_input":"2022-11-09T02:58:44.633761Z","iopub.status.idle":"2022-11-09T02:58:46.802091Z","shell.execute_reply.started":"2022-11-09T02:58:44.633697Z","shell.execute_reply":"2022-11-09T02:58:46.801127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define key variables","metadata":{}},{"cell_type":"code","source":"filepath = '/kaggle/input/shoe-vs-sandal-vs-boot-dataset-15k-images/Shoe vs Sandal vs Boot Dataset'\ntest_size = 0.2\ndev_size = 0.2\nn_H = 102\nn_W = 136\nepochs = 30\nlearning_rate=0.0007\nrandom.seed(6278)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T02:58:46.806495Z","iopub.execute_input":"2022-11-09T02:58:46.806738Z","iopub.status.idle":"2022-11-09T02:58:46.811948Z","shell.execute_reply.started":"2022-11-09T02:58:46.806714Z","shell.execute_reply":"2022-11-09T02:58:46.810822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import Data\n\nUsing the cv2 package, read in each file and append it to a normal list to create X data. For each file being read append the folder name which specifies the shoe_type label to Y variable.\n\nAs experienced later in development, not all images are of the specified 136x102 pixels so, in reading in the images, all will be resized with skimage to these dimensions such that they are of equal size later.","metadata":{}},{"cell_type":"code","source":"X = []\nY = []\n\nfor shoe_folder in os.scandir(filepath): # iterate through subfolders\n    shoe_type = os.path.basename(shoe_folder) # Save folder name string for use as shoe label\n    pbar = tqdm(os.scandir(shoe_folder.path), total=5000) # Use tqdm iter to display progress of reading in images\n    \n    for file in pbar: # iterate through files\n        pbar.set_description(f\"Processing {shoe_type} Images\")\n        img = cv2.imread(file.path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # transform defualt read in of cv2 BGR to RGB\n        img_array = np.asarray(img)\n        \n        if img_array.shape != (102,136,3): # Do conditional resizing to save computing power\n            img_array = resize(img_array, [n_H,n_W], anti_aliasing=True) # resize to ensure all images are 136 x 102\n            \n        X.append(img_array)\n        Y.append(shoe_type)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T02:58:46.813436Z","iopub.execute_input":"2022-11-09T02:58:46.813754Z","iopub.status.idle":"2022-11-09T03:00:24.264215Z","shell.execute_reply.started":"2022-11-09T02:58:46.81372Z","shell.execute_reply":"2022-11-09T03:00:24.26279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_Y = list(zip(X,Y)) # Zip images and associated label\nrandom.shuffle(X_Y) # Shuffle\nX, Y = zip(*X_Y) # Unzip back into X and Y","metadata":{"execution":{"iopub.status.busy":"2022-11-09T03:00:24.267022Z","iopub.execute_input":"2022-11-09T03:00:24.267382Z","iopub.status.idle":"2022-11-09T03:00:24.296349Z","shell.execute_reply.started":"2022-11-09T03:00:24.267353Z","shell.execute_reply":"2022-11-09T03:00:24.294998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize shuffled images\nLets take a look at the first 20 images in the shuffled data.  Their Y label is used as the subplot title","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(4,5, figsize=[18,8])\nfor i in range(20):\n    ax = axs[i//5, i%5]\n    ax.imshow(X[i])\n    ax.axis('off')\n    ax.set_title(Y[i])\n    \nfig.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-09T03:00:24.298197Z","iopub.execute_input":"2022-11-09T03:00:24.299144Z","iopub.status.idle":"2022-11-09T03:00:25.255335Z","shell.execute_reply.started":"2022-11-09T03:00:24.299096Z","shell.execute_reply":"2022-11-09T03:00:25.254434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split Data into Train-Dev-Test\nSteps:\n* Convert list of nparray into singular nparrays\n* One-Hot Encode Y-label\n* Split into Train-Dev-Test\n* Delete unused arrays to save on memory","metadata":{}},{"cell_type":"code","source":"num_dev = int(len(X) * dev_size) \nnum_test = int(len(X) * test_size)\n\nX_arr = np.asarray(X) / 255\nY_arr = np.asarray(Y).reshape(-1,1)\n\ndel X, Y\n\nohe = OneHotEncoder(categories='auto', sparse=False)\nY_ohe = ohe.fit_transform(Y_arr)\n\nX_train = X_arr[:-(num_test + num_dev)]\nX_dev = X_arr[-(num_test + num_dev):-num_test]\nX_test = X_arr[-num_test:]\n\nY_train = Y_ohe[:-(num_test + num_dev)]\nY_dev = Y_ohe[-(num_test + num_dev):-num_test]\nY_test = Y_ohe[-num_test:]\n\ndel X_arr, Y_arr, Y_ohe\n\nprint(\"Training X:\", X_train.shape)\nprint(\"Training Y:\", Y_train.shape)\nprint(\"Development X:\", X_dev.shape)\nprint(\"Development Y:\", Y_dev.shape)\nprint(\"Test X:\", X_test.shape)\nprint(\"Test Y:\", Y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T03:00:25.256419Z","iopub.execute_input":"2022-11-09T03:00:25.256901Z","iopub.status.idle":"2022-11-09T03:00:26.451591Z","shell.execute_reply.started":"2022-11-09T03:00:25.256873Z","shell.execute_reply":"2022-11-09T03:00:26.450378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building the Convolution Neural Network (Version 1)\n\nThis is my first attempt at a CNN for this problem.  I am using 3 Conv2D and 3 MaxPool layers alternated followed up by three Dense layers with the final layer being a softmax output. Additionally, I have added 3 Dropout Layers within the model to better assist with variance between train and test.\n\nA key trait in my choices of Conv2D and MaxPool layers was to not lose any data at the edges of the image in the event the filter and stride would extend beyond the image.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential(name = 'FirstModel')\n\nmodel.add(layers.Conv2D(\n    filters=8,\n    kernel_size=7,\n    activation='relu',\n    strides=2,\n    padding='same',\n    input_shape=(n_H, n_W, 3),\n    name='Conv1'))\n\nmodel.add(layers.MaxPool2D(\n    pool_size=(2, 2),\n    strides=None,\n    padding='same',\n    name='MaxPool1'))\n\nmodel.add(layers.Conv2D(\n    filters=16, \n    kernel_size=3, \n    activation='relu', \n    strides=1, \n    padding='valid',\n    name='Conv2'))\n\nmodel.add(layers.MaxPool2D(\n    pool_size=(2, 2),\n    strides=None,\n    padding='valid',\n    name='MaxPool2'))\n\nmodel.add(layers.Dropout(.2, name='Dropout1'))\n\nmodel.add(layers.Conv2D(\n    filters=32, \n    kernel_size=5, \n    activation='relu', \n    strides=1, \n    padding='same',\n    name='Conv3'))\n\nmodel.add(layers.MaxPool2D(\n    pool_size=(2, 2), \n    strides=None,\n    padding='valid',\n    name='MaxPool3'))\n\nmodel.add(layers.Flatten(name='Flatten'))\n\nmodel.add(layers.Dropout(.2, name='Dropout2'))\n\nmodel.add(layers.Dense(128,activation='relu',name='Dense1'))\n\nmodel.add(layers.Dropout(.2, name='Dropout3'))\n\nmodel.add(layers.Dense(32, activation='relu', name='Dense2'))\n\nmodel.add(layers.Dense(3, activation='softmax', name='Dense3'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-09T03:00:26.453154Z","iopub.execute_input":"2022-11-09T03:00:26.453626Z","iopub.status.idle":"2022-11-09T03:00:26.640369Z","shell.execute_reply.started":"2022-11-09T03:00:26.453591Z","shell.execute_reply":"2022-11-09T03:00:26.639702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I am using the Adam Optimizer with a set learning rate lower than default as it seemed the default was a little unstable in training.","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])\n\nhistory = model.fit(X_train, Y_train, validation_data=(X_dev, Y_dev), epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T03:00:26.641668Z","iopub.execute_input":"2022-11-09T03:00:26.642165Z","iopub.status.idle":"2022-11-09T03:04:15.925386Z","shell.execute_reply.started":"2022-11-09T03:00:26.642133Z","shell.execute_reply":"2022-11-09T03:04:15.924136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Summarize Results\nBelow you can see the training and validation losses over training. The Losses and Accuracies of the validation set were showing minimal improvement so there could have been more epochs of training if desired. The model is not overfitting the training data.","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16,6))\ntitle_fontsize = 16\naxis_fontsize = 12\n\nax1.plot(range(1,epochs+1), history.history['loss'], label='Training loss')\nax1.plot(range(1,epochs+1), history.history['val_loss'], label='Validation Loss')\nax1.legend()\nax1.set_xticks(range(1,epochs+1,3))\nax1.set_title('Loss', fontsize=title_fontsize)\nax1.set_xlabel('Epoch', fontsize=axis_fontsize)\n\nax2.plot(range(1,epochs+1), history.history['accuracy'], label='Training Accuracy')\nax2.plot(range(1,epochs+1), history.history['val_accuracy'], label='Validation Accuracy')\nax2.legend()\nax2.set_xticks(range(1,epochs+1,3))\nax2.set_title('Accuracy', fontsize=title_fontsize)\nax2.set_xlabel('Epoch', fontsize=axis_fontsize);\n","metadata":{"execution":{"iopub.status.busy":"2022-11-09T03:04:15.927552Z","iopub.execute_input":"2022-11-09T03:04:15.927995Z","iopub.status.idle":"2022-11-09T03:04:16.260257Z","shell.execute_reply.started":"2022-11-09T03:04:15.92796Z","shell.execute_reply":"2022-11-09T03:04:16.259251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The evaluation of the test data shows close results to the dev set as well, which is a good result.  Overall, on a train-dev-test 60/20/20 split, this model has achieved an **accuracy of 97.5%!**","metadata":{}},{"cell_type":"code","source":"score = model.evaluate(X_test, Y_test)\nprint(\"Test loss:\", score[0])\nprint(\"Test accuracy:\", score[1])","metadata":{"execution":{"iopub.status.busy":"2022-11-09T03:04:16.261578Z","iopub.execute_input":"2022-11-09T03:04:16.26186Z","iopub.status.idle":"2022-11-09T03:04:17.609163Z","shell.execute_reply.started":"2022-11-09T03:04:16.261835Z","shell.execute_reply":"2022-11-09T03:04:17.607527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Error Analysis\nIt is a good idea to examine what are examples of incorrectly labeled outputs to see if there is a certain characteristic of this input data that your model is performing poorly on. Below I will look a confusion matrix of the different outputs as well as a few of the incorrectly labeled results in the test set.","metadata":{}},{"cell_type":"code","source":"Y_pred = model.predict(X_test)\nY_pred_max = Y_pred.max(axis=1,keepdims=True)\nY_pred = (Y_pred_max == Y_pred).astype(int)\nY_test_labels = ohe.inverse_transform(Y_test)\nY_pred_labels = ohe.inverse_transform(Y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T03:04:17.611107Z","iopub.execute_input":"2022-11-09T03:04:17.611479Z","iopub.status.idle":"2022-11-09T03:04:18.947846Z","shell.execute_reply.started":"2022-11-09T03:04:17.611446Z","shell.execute_reply":"2022-11-09T03:04:18.947125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = labels=[\"Shoe\", \"Sandal\", \"Boot\"]\ncm = confusion_matrix(Y_test_labels, Y_pred_labels, labels=labels, normalize='true') * 100\n\n\n\nCM = pd.DataFrame(cm,\n                  columns = [label+'_pred' for label in labels],\n                  index = [label+'_true' for label in labels]).copy()\n\nnp.fill_diagonal(cm, 0)\ncm = cm *100 / cm.sum()\nsns.heatmap(cm, annot=True, cmap=\"crest\")\nplt.title('Heatmap of Incorrect Predictions')\n\nCM\n","metadata":{"execution":{"iopub.status.busy":"2022-11-09T03:04:18.949091Z","iopub.execute_input":"2022-11-09T03:04:18.949532Z","iopub.status.idle":"2022-11-09T03:04:19.176376Z","shell.execute_reply.started":"2022-11-09T03:04:18.949504Z","shell.execute_reply":"2022-11-09T03:04:19.174919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Over 40% of the incorrect guesses are coming from the model incorrectly predicting sandals as shoes. For further improvement to the model, I would focus on what is causing this discrepancy","metadata":{}},{"cell_type":"code","source":"prediction_df = pd.DataFrame(zip(Y_pred_labels[:,0], Y_test_labels[:,0]), columns=['Pred', 'True'])\nprediction_df['Correct'] = prediction_df['Pred'] == prediction_df['True']\nincorrect_predictions = list(prediction_df[prediction_df['Correct'] == False].index)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T03:04:19.179491Z","iopub.execute_input":"2022-11-09T03:04:19.17986Z","iopub.status.idle":"2022-11-09T03:04:19.205254Z","shell.execute_reply.started":"2022-11-09T03:04:19.179827Z","shell.execute_reply":"2022-11-09T03:04:19.20372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(6,5, figsize=[18,11])\nfor i, inpred in enumerate(incorrect_predictions[:30]):\n    ax = axs[i//5, i%5]\n    ax.imshow(X_test[inpred])\n    ax.axis('off')\n    ax.set_title(Y_pred_labels[inpred][0], fontsize=14, color=\"darkred\")\n    \nfig.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-09T03:04:19.207764Z","iopub.execute_input":"2022-11-09T03:04:19.208212Z","iopub.status.idle":"2022-11-09T03:04:20.499373Z","shell.execute_reply.started":"2022-11-09T03:04:19.208177Z","shell.execute_reply":"2022-11-09T03:04:20.498039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Error Analysis\n\nLooking at this subsample of incorrectly predict labels, there seems to be a few trends:\n* Incorrectly labeling sandals as shoes when there is a lot of material that covers the top of the foot\n* Incorrectly labeling as boots for any shoe or sandal with high tops\n* Incorrectly labeling as sandals when either design or laces has appears as thick stripes across top.","metadata":{}}]}